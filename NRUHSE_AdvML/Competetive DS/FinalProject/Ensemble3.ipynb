{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 600)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "#import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "#import matplotlib.dates as mdates\n",
    "%matplotlib inline \n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from itertools import product\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = './data/'\n",
    "\n",
    "sales = pd.read_csv(os.path.join(DATA_FOLDER, 'sales_train.csv.gz'))\n",
    "test = pd.read_csv(os.path.join(DATA_FOLDER, 'test.csv.gz'))\n",
    "items = pd.read_csv(os.path.join(DATA_FOLDER, 'items.csv'))\n",
    "categories = pd.read_csv(os.path.join(DATA_FOLDER, 'item_categories.csv'))\n",
    "shops = pd.read_csv(os.path.join(DATA_FOLDER, 'shops.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast_dtypes(df):\n",
    "    '''\n",
    "        Changes column types in the dataframe: \n",
    "                \n",
    "                `float64` type to `float32`\n",
    "                `int64`   type to `int32`\n",
    "    '''\n",
    "    \n",
    "    # Select columns to downcast\n",
    "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "    int_cols =   [c for c in df if df[c].dtype == \"int64\"]\n",
    "    \n",
    "    # Downcast\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols]   = df[int_cols].astype(np.int32)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_category_mapping = items[['item_id','item_category_id']].drop_duplicates()\n",
    "index_cols = ['shop_id', 'item_id', 'date_block_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid(sales, index_cols):\n",
    "    from tqdm import tqdm_notebook\n",
    "    \n",
    "    # For every month we create a grid from all shops/items combinations from that month\n",
    "    grid = [] \n",
    "    for block_num in tqdm_notebook(sales['date_block_num'].unique()):\n",
    "        cur_shops = sales.loc[sales['date_block_num'] == block_num, 'shop_id'].unique()\n",
    "        cur_items = sales.loc[sales['date_block_num'] == block_num, 'item_id'].unique()\n",
    "        grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n",
    "\n",
    "    # Turn the grid into a dataframe\n",
    "    grid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)\n",
    "\n",
    "    # Groupby data to get shop-item-month aggregates\n",
    "    gb = sales.groupby(index_cols,as_index=False).agg({'item_cnt_day':{'target':'sum'}})\n",
    "    # Fix column names\n",
    "    gb.columns = [col[0] if col[-1]=='' else col[-1] for col in gb.columns.values] \n",
    "    # Clip\n",
    "    gb.target = gb.target.clip(0,20) #TODO\n",
    "    # Join it to the grid    \n",
    "    all_data = pd.merge(grid, gb, how='left', on=index_cols).fillna(0)\n",
    "\n",
    "    # Same as above but with shop-month aggregates\n",
    "    gb = sales.groupby(['shop_id', 'date_block_num'],as_index=False).agg({'item_cnt_day':{'target_shop':'sum'}})\n",
    "    gb.columns = [col[0] if col[-1]=='' else col[-1] for col in gb.columns.values]\n",
    "    all_data = pd.merge(all_data, gb, how='left', on=['shop_id', 'date_block_num']).fillna(0)\n",
    "\n",
    "    # Same as above but with item-month aggregates\n",
    "    gb = sales.groupby(['item_id', 'date_block_num'],as_index=False).agg({'item_cnt_day':{'target_item':'sum'}})\n",
    "    gb.columns = [col[0] if col[-1] == '' else col[-1] for col in gb.columns.values]\n",
    "    all_data = pd.merge(all_data, gb, how='left', on=['item_id', 'date_block_num']).fillna(0)\n",
    "\n",
    "    # Same as above but with category-month aggregates\n",
    "    all_data = pd.merge(all_data, item_category_mapping, how='left', on='item_id')\n",
    "    \n",
    "    gb = pd.merge(sales, item_category_mapping, how='left', on='item_id')\n",
    "    gb = gb.groupby(['item_category_id', 'date_block_num'],as_index=False).agg({'item_cnt_day':{'target_category':'sum'}})\n",
    "    gb.columns = [col[0] if col[-1] == '' else col[-1] for col in gb.columns.values]\n",
    "    all_data = pd.merge(all_data, gb, how='left', on=['item_category_id', 'date_block_num']).fillna(0)\n",
    "    all_data = all_data.drop(['item_category_id'], axis=1)\n",
    "\n",
    "    # Downcast dtypes from 64 to 32 bit to save memory\n",
    "    all_data = downcast_dtypes(all_data)\n",
    "    del grid, gb \n",
    "    gc.collect();\n",
    "    \n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_train_date_block_num = sales.date_block_num.max()\n",
    "max_train_date_block_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d16b4846d64abe9cd1059b012b9616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=35), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/groupby/groupby.py:4658: FutureWarning: using a dict with renaming is deprecated and will be removed in a future version\n",
      "  return super(DataFrameGroupBy, self).aggregate(arg, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>target</th>\n",
       "      <th>target_shop</th>\n",
       "      <th>target_item</th>\n",
       "      <th>target_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>22154</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6094.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59</td>\n",
       "      <td>2552</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>287.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59</td>\n",
       "      <td>2554</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>287.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59</td>\n",
       "      <td>2555</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>268.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>2564</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>701.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shop_id  item_id  date_block_num  target  target_shop  target_item  \\\n",
       "0       59    22154               0     1.0       2017.0         18.0   \n",
       "1       59     2552               0     0.0       2017.0          0.0   \n",
       "2       59     2554               0     0.0       2017.0          1.0   \n",
       "3       59     2555               0     0.0       2017.0          2.0   \n",
       "4       59     2564               0     0.0       2017.0          5.0   \n",
       "\n",
       "   target_category  \n",
       "0           6094.0  \n",
       "1            287.0  \n",
       "2            287.0  \n",
       "3            268.0  \n",
       "4            701.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = create_grid(\n",
    "    pd.concat(\n",
    "        [sales, test.assign(date_block_num=max_train_date_block_num+1)],\n",
    "        ignore_index=True, sort=False),\n",
    "    index_cols)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lags(all_data, shift_range = [1, 2, 3, 4, 5, 12]):\n",
    "\n",
    "    # List of columns that we will use to create lags\n",
    "    cols_to_rename = list(all_data.columns.difference(index_cols)) \n",
    "\n",
    "    for month_shift in tqdm_notebook(shift_range):\n",
    "        train_shift = all_data[index_cols + cols_to_rename].copy()\n",
    "\n",
    "        train_shift['date_block_num'] = train_shift['date_block_num'] + month_shift\n",
    "\n",
    "        foo = lambda x: '{}_lag_{}'.format(x, month_shift) if x in cols_to_rename else x\n",
    "        train_shift = train_shift.rename(columns=foo)\n",
    "\n",
    "        all_data = pd.merge(all_data, train_shift, on=index_cols, how='left').fillna(0)\n",
    "\n",
    "    del train_shift\n",
    "\n",
    "    # List of all lagged features\n",
    "    fit_cols = [col for col in all_data.columns if col[-1] in [str(item) for item in shift_range]]  \n",
    "    # We will drop these at fitting stage\n",
    "    to_drop_cols = list(set(list(all_data.columns)) - (set(fit_cols)|set(index_cols))) + ['date_block_num'] \n",
    "    \n",
    "    all_data = pd.merge(all_data, item_category_mapping, how='left', on='item_id')\n",
    "\n",
    "    all_data = downcast_dtypes(all_data)\n",
    "    gc.collect();\n",
    "    \n",
    "    return all_data, to_drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8187a2e0246a42f1a988ce84c8539eb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>target</th>\n",
       "      <th>target_shop</th>\n",
       "      <th>target_item</th>\n",
       "      <th>target_category</th>\n",
       "      <th>target_lag_1</th>\n",
       "      <th>target_category_lag_1</th>\n",
       "      <th>target_item_lag_1</th>\n",
       "      <th>target_shop_lag_1</th>\n",
       "      <th>target_lag_2</th>\n",
       "      <th>target_category_lag_2</th>\n",
       "      <th>target_item_lag_2</th>\n",
       "      <th>target_shop_lag_2</th>\n",
       "      <th>target_lag_3</th>\n",
       "      <th>target_category_lag_3</th>\n",
       "      <th>target_item_lag_3</th>\n",
       "      <th>target_shop_lag_3</th>\n",
       "      <th>target_lag_4</th>\n",
       "      <th>target_category_lag_4</th>\n",
       "      <th>target_item_lag_4</th>\n",
       "      <th>target_shop_lag_4</th>\n",
       "      <th>target_lag_5</th>\n",
       "      <th>target_category_lag_5</th>\n",
       "      <th>target_item_lag_5</th>\n",
       "      <th>target_shop_lag_5</th>\n",
       "      <th>target_lag_12</th>\n",
       "      <th>target_category_lag_12</th>\n",
       "      <th>target_item_lag_12</th>\n",
       "      <th>target_shop_lag_12</th>\n",
       "      <th>item_category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>22154</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6094.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59</td>\n",
       "      <td>2552</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59</td>\n",
       "      <td>2554</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59</td>\n",
       "      <td>2555</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>2564</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>701.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shop_id  item_id  date_block_num  target  target_shop  target_item  \\\n",
       "0       59    22154               0     1.0       2017.0         18.0   \n",
       "1       59     2552               0     0.0       2017.0          0.0   \n",
       "2       59     2554               0     0.0       2017.0          1.0   \n",
       "3       59     2555               0     0.0       2017.0          2.0   \n",
       "4       59     2564               0     0.0       2017.0          5.0   \n",
       "\n",
       "   target_category  target_lag_1  target_category_lag_1  target_item_lag_1  \\\n",
       "0           6094.0           0.0                    0.0                0.0   \n",
       "1            287.0           0.0                    0.0                0.0   \n",
       "2            287.0           0.0                    0.0                0.0   \n",
       "3            268.0           0.0                    0.0                0.0   \n",
       "4            701.0           0.0                    0.0                0.0   \n",
       "\n",
       "   target_shop_lag_1  target_lag_2  target_category_lag_2  target_item_lag_2  \\\n",
       "0                0.0           0.0                    0.0                0.0   \n",
       "1                0.0           0.0                    0.0                0.0   \n",
       "2                0.0           0.0                    0.0                0.0   \n",
       "3                0.0           0.0                    0.0                0.0   \n",
       "4                0.0           0.0                    0.0                0.0   \n",
       "\n",
       "   target_shop_lag_2  target_lag_3  target_category_lag_3  target_item_lag_3  \\\n",
       "0                0.0           0.0                    0.0                0.0   \n",
       "1                0.0           0.0                    0.0                0.0   \n",
       "2                0.0           0.0                    0.0                0.0   \n",
       "3                0.0           0.0                    0.0                0.0   \n",
       "4                0.0           0.0                    0.0                0.0   \n",
       "\n",
       "   target_shop_lag_3  target_lag_4  target_category_lag_4  target_item_lag_4  \\\n",
       "0                0.0           0.0                    0.0                0.0   \n",
       "1                0.0           0.0                    0.0                0.0   \n",
       "2                0.0           0.0                    0.0                0.0   \n",
       "3                0.0           0.0                    0.0                0.0   \n",
       "4                0.0           0.0                    0.0                0.0   \n",
       "\n",
       "   target_shop_lag_4  target_lag_5  target_category_lag_5  target_item_lag_5  \\\n",
       "0                0.0           0.0                    0.0                0.0   \n",
       "1                0.0           0.0                    0.0                0.0   \n",
       "2                0.0           0.0                    0.0                0.0   \n",
       "3                0.0           0.0                    0.0                0.0   \n",
       "4                0.0           0.0                    0.0                0.0   \n",
       "\n",
       "   target_shop_lag_5  target_lag_12  target_category_lag_12  \\\n",
       "0                0.0            0.0                     0.0   \n",
       "1                0.0            0.0                     0.0   \n",
       "2                0.0            0.0                     0.0   \n",
       "3                0.0            0.0                     0.0   \n",
       "4                0.0            0.0                     0.0   \n",
       "\n",
       "   target_item_lag_12  target_shop_lag_12  item_category_id  \n",
       "0                 0.0                 0.0                37  \n",
       "1                 0.0                 0.0                58  \n",
       "2                 0.0                 0.0                58  \n",
       "3                 0.0                 0.0                56  \n",
       "4                 0.0                 0.0                59  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['target_item', 'target', 'target_shop', 'target_category', 'date_block_num']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lagged_data, to_drop_cols = create_lags(all_data)\n",
    "lagged_data.head()\n",
    "to_drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO shop_id one-hot encoding, category_id one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = lagged_data.loc[lagged_data.date_block_num <= max_train_date_block_num]\n",
    "test_lagged = lagged_data.loc[lagged_data.date_block_num == max_train_date_block_num + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "#train = train.loc[train.shop_id.isin([26, 27, 28])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.9000e+01 2.2154e+04 0.0000e+00 ... 0.0000e+00 0.0000e+00 3.7000e+01]\n",
      " [5.9000e+01 2.5520e+03 0.0000e+00 ... 0.0000e+00 0.0000e+00 5.8000e+01]\n",
      " [5.9000e+01 2.5540e+03 0.0000e+00 ... 0.0000e+00 0.0000e+00 5.8000e+01]\n",
      " ...\n",
      " [2.1000e+01 7.6400e+03 0.0000e+00 ... 0.0000e+00 0.0000e+00 6.4000e+01]\n",
      " [2.1000e+01 7.6320e+03 0.0000e+00 ... 0.0000e+00 0.0000e+00 6.4000e+01]\n",
      " [2.1000e+01 7.4400e+03 0.0000e+00 ... 0.0000e+00 0.0000e+00 5.7000e+01]]\n"
     ]
    }
   ],
   "source": [
    "X_train = train.drop(to_drop_cols, axis=1).values\n",
    "print(X_train) #X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "target_col = 'target'\n",
    "y_train = train.loc[:, [target_col]].values.ravel()\n",
    "print(y_train) #y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_time_split(data, n_splits):\n",
    "    for i in range(n_splits):\n",
    "        #print(i)\n",
    "        first_vali_date_block_num = max_train_date_block_num - i\n",
    "        vali_indices = data.loc[:,'date_block_num'] == first_vali_date_block_num\n",
    "        train_indices = data.loc[:,'date_block_num'] < first_vali_date_block_num\n",
    "        yield (train_indices[train_indices].index.values, vali_indices[vali_indices].index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = gen_time_split(train, 3)\n",
    "#for (tidx, vidx) in cv:\n",
    "#    print(X_train[tidx])\n",
    "#    print(X_train[vidx])\n",
    "#    print(y_train[tidx])\n",
    "#    print(y_train[vidx])\n",
    "#for split in cv:\n",
    "#    print(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr = 1 / np.logspace(0.0, 1.0, num=5)[2:]\n",
    "#lr = np.array([0.3, 0.45, 0.6])\n",
    "#lr = np.linspace(0.3, 0.6, 5)\n",
    "lr = np.array([0.3])\n",
    "print(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.0000e+00 5.0370e+03 0.0000e+00 ... 6.5000e+01 1.4450e+03 1.9000e+01]\n",
      " [5.0000e+00 5.3200e+03 0.0000e+00 ... 0.0000e+00 0.0000e+00 5.5000e+01]\n",
      " [5.0000e+00 5.2330e+03 1.0000e+00 ... 0.0000e+00 0.0000e+00 1.9000e+01]\n",
      " ...\n",
      " [4.5000e+01 1.5757e+04 0.0000e+00 ... 9.0000e+00 1.2510e+03 5.5000e+01]\n",
      " [4.5000e+01 1.9648e+04 0.0000e+00 ... 0.0000e+00 0.0000e+00 4.0000e+01]\n",
      " [4.5000e+01 9.6900e+02 0.0000e+00 ... 6.0000e+00 1.2510e+03 3.7000e+01]]\n"
     ]
    }
   ],
   "source": [
    "X_test = test.merge(test_lagged, how='left').drop(to_drop_cols + ['ID'], axis=1).values\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "params = {'max_depth':7, 'eta':0.3, 'silent':0, 'objective':'reg:linear', 'eval_metric':'rmse'}\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = [fold for fold in gen_time_split(train, 3)]\n",
    "#print(folds)\n",
    "eval_hist = xgb.cv(param, dtrain, num_boost_round=1000, folds=folds, metrics=['rmse'], early_stopping_rounds=10, verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_num_rounds = eval_hist.shape[0]\n",
    "#eval_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:25:32] /mnt/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 248 extra nodes, 0 pruned nodes, max_depth=7\n",
      "[21:25:35] /mnt/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 254 extra nodes, 0 pruned nodes, max_depth=7\n",
      "[21:25:38] /mnt/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 254 extra nodes, 0 pruned nodes, max_depth=7\n",
      "[21:25:42] /mnt/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 254 extra nodes, 0 pruned nodes, max_depth=7\n",
      "[21:25:45] /mnt/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 254 extra nodes, 0 pruned nodes, max_depth=7\n",
      "[21:25:49] /mnt/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 250 extra nodes, 0 pruned nodes, max_depth=7\n",
      "[21:25:52] /mnt/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 248 extra nodes, 0 pruned nodes, max_depth=7\n",
      "[21:25:55] /mnt/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 254 extra nodes, 0 pruned nodes, max_depth=7\n",
      "[21:25:59] /mnt/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 250 extra nodes, 0 pruned nodes, max_depth=7\n",
      "[21:26:02] /mnt/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 246 extra nodes, 0 pruned nodes, max_depth=7\n",
      "[21:26:06] /mnt/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 222 extra nodes, 0 pruned nodes, max_depth=7\n",
      "[21:26:09] /mnt/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 248 extra nodes, 0 pruned nodes, max_depth=7\n",
      "[21:26:12] /mnt/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 248 extra nodes, 0 pruned nodes, max_depth=7\n",
      "[21:26:16] /mnt/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 236 extra nodes, 0 pruned nodes, max_depth=7\n",
      "[21:26:18] /mnt/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 250 extra nodes, 0 pruned nodes, max_depth=7\n",
      "[21:26:22] /mnt/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 242 extra nodes, 0 pruned nodes, max_depth=7\n",
      "[21:26:25] /mnt/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 252 extra nodes, 0 pruned nodes, max_depth=7\n",
      "[21:26:29] /mnt/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 248 extra nodes, 0 pruned nodes, max_depth=7\n",
      "[21:26:32] /mnt/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 218 extra nodes, 0 pruned nodes, max_depth=7\n",
      "[21:26:35] /mnt/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 240 extra nodes, 0 pruned nodes, max_depth=7\n",
      "[21:26:39] /mnt/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 220 extra nodes, 0 pruned nodes, max_depth=7\n",
      "[21:26:43] /mnt/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 250 extra nodes, 0 pruned nodes, max_depth=7\n",
      "[21:26:46] /mnt/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 228 extra nodes, 0 pruned nodes, max_depth=7\n",
      "[21:26:49] /mnt/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 230 extra nodes, 0 pruned nodes, max_depth=7\n",
      "[21:26:52] /mnt/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 240 extra nodes, 0 pruned nodes, max_depth=7\n",
      "[21:26:55] /mnt/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 240 extra nodes, 0 pruned nodes, max_depth=7\n",
      "[21:26:59] /mnt/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 248 extra nodes, 0 pruned nodes, max_depth=7\n",
      "[21:27:02] /mnt/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 246 extra nodes, 0 pruned nodes, max_depth=7\n",
      "[21:27:05] /mnt/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 244 extra nodes, 0 pruned nodes, max_depth=7\n",
      "[21:27:09] /mnt/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 234 extra nodes, 0 pruned nodes, max_depth=7\n",
      "[21:27:12] /mnt/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 236 extra nodes, 0 pruned nodes, max_depth=7\n",
      "[21:27:16] /mnt/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 216 extra nodes, 0 pruned nodes, max_depth=7\n",
      "[21:27:19] /mnt/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 192 extra nodes, 0 pruned nodes, max_depth=7\n",
      "[21:27:22] /mnt/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 128 extra nodes, 0 pruned nodes, max_depth=7\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.train(params, dtrain, num_boost_round=34)#opt_num_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for XGBoost is 0.902616\n",
      "Train R-squared for XGBoost is 0.454747\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "y_train_pred_xgb = xgb_model.predict(dtrain)\n",
    "print('RMSE for XGBoost is %f' % np.sqrt(mean_squared_error(y_train, y_train_pred_xgb)))\n",
    "print('Train R-squared for XGBoost is %f' % r2_score(y_train, y_train_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE for XGBoost is 0.857923\n",
    "Train R-squared for XGBoost is 0.507406"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "plot_importance(xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5309142  0.14552623 0.87035084 ... 0.04141507 0.04115519 0.01889181]\n"
     ]
    }
   ],
   "source": [
    "# make prediction\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "y_test_pred_xgb = xgb_model.predict(dtest)\n",
    "print(y_test_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_train, y_train_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_cnt_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>214200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.277889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.739555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.609954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.027626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.104150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.273682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21.945091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       item_cnt_month\n",
       "count   214200.000000\n",
       "mean         0.277889\n",
       "std          0.739555\n",
       "min         -1.609954\n",
       "25%          0.027626\n",
       "50%          0.104150\n",
       "75%          0.273682\n",
       "max         21.945091"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = test.assign(item_cnt_month=y_test_pred_xgb)[['item_cnt_month']]\n",
    "submission.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('Ensemble3.csv', index_label='ID') #header=['ID', 'item_cnt_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline.ipynb\t  Ensemble3.csv.gz  Refactor.ipynb\r\n",
      "Combos.ipynb\t  Ensemble3.ipynb   RefactorXGB.csv.gz\r\n",
      "data\t\t  Ensemble.csv.gz   Shop and item category means.ipynb\r\n",
      "EDA.ipynb\t  Ensemble.ipynb\r\n",
      "Ensemble2.csv.gz  Lagged.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!gzip Ensemble3.csv\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "def create_keras_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "keras_estimator = KerasRegressor(build_fn=create_keras_model, epochs=10, batch_size=1000, verbose=True)\n",
    "#results = cross_val_score(estimator, X_train, Y_train, cv=gen_time_split(train, 3))\n",
    "model_keras = keras_estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "y_train_pred_keras = keras_estimator.predict(X_train)\n",
    "print('RMSE for Keras is %f' % np.sqrt(mean_squared_error(y_train, y_train_pred_keras)))\n",
    "print('Train R-squared for Keras is %f' % r2_score(y_train, y_train_pred_keras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
